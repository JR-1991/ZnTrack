{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9619a90b-bbb8-4cd9-8104-9e9fb6c184eb",
   "metadata": {},
   "source": [
    "# TensorFlow Example\n",
    "\n",
    "These tutorial is based on https://www.tensorflow.org/tutorials/quickstart/beginner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "057b22b9-966b-460f-9c95-678b6c3d2d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ExampleTensorflow01 import LoadData, FitModel, EvaluateModel\n",
    "from tempfile import TemporaryDirectory\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "temp_dir = TemporaryDirectory()\n",
    "shutil.copy('ExampleTensorflow01.py', temp_dir.name)\n",
    "os.chdir(temp_dir.name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "89dd63a7-1b95-40f6-9047-c71bdd8516b2",
   "metadata": {},
   "source": [
    "1. Initalize GIT and DVC\n",
    "\n",
    "We are using a temporary directory for test reasons and will delete it at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized empty Git repository in C:/Users/fabia/AppData/Local/Temp/tmp41lt62w5/.git/\n",
      "Initialized DVC repository.\n",
      "\n",
      "You can now commit the changes to git.\n",
      "\n",
      "+---------------------------------------------------------------------+\n",
      "|                                                                     |\n",
      "|        DVC has enabled anonymous aggregate usage analytics.         |\n",
      "|     Read the analytics documentation (and how to opt-out) here:     |\n",
      "|             <https://dvc.org/doc/user-guide/analytics>              |\n",
      "|                                                                     |\n",
      "+---------------------------------------------------------------------+\n",
      "\n",
      "What's next?\n",
      "------------\n",
      "- Check out the documentation: <https://dvc.org/doc>\n",
      "- Get help and share ideas: <https://dvc.org/chat>\n",
      "- Star us on GitHub: <https://github.com/iterative/dvc>\n"
     ]
    }
   ],
   "source": [
    "!git init\n",
    "!dvc init"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "d122054c-a7b2-49d9-950b-865256657f4e",
   "metadata": {},
   "source": [
    "*Content of ExampleTensorflow01.py:LoadData*\n",
    "```python\n",
    "from pytrack import PyTrack, DVCParams\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class LoadData(PyTrack):\n",
    "    def __init__(self, id_=None, filter_=None):\n",
    "        super().__init__()\n",
    "        self.dvc = DVCParams(\n",
    "            outs=['x_train.npy', 'y_train.npy', 'x_test.npy', 'y_test.npy']\n",
    "        )\n",
    "        self.post_init(id_, filter_)\n",
    "\n",
    "    def __call__(self, dataset: str, exec_: bool = False, slurm: bool = False, force: bool = False,\n",
    "                 always_changed: bool = False):\n",
    "        self.parameters = {\"dataset\": dataset}\n",
    "        self.post_call(exec_=exec_, slurm=slurm, force=force, always_changed=always_changed)\n",
    "\n",
    "    def run(self):\n",
    "        self.pre_run()\n",
    "\n",
    "        if self.parameters['dataset'] == \"mnist\":\n",
    "            mnist = tf.keras.datasets.mnist\n",
    "            (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "            x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "            with open(self.files.outs[0], \"wb\") as f:\n",
    "                np.save(f, x_train)\n",
    "            with open(self.files.outs[1], \"wb\") as f:\n",
    "                np.save(f, y_train)\n",
    "            with open(self.files.outs[2], \"wb\") as f:\n",
    "                np.save(f, x_test)\n",
    "            with open(self.files.outs[3], \"wb\") as f:\n",
    "                np.save(f, y_test)\n",
    "\n",
    "            self.results = {\"shape\": x_train.shape, \"targets\": len(np.unique(y_train))}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07cbd75-421c-48b5-abfe-afe04c2f8ba7",
   "metadata": {},
   "source": [
    "2. Create an instance of the first stage.\n",
    "\n",
    "Calling the stage runs the dvc command. Because on default it uses `--no-exec` it will only create the stage for us, but won't execute it.\n",
    "Also for simplicity reasons we have only a single parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59b2a367-a856-4480-88f4-7e4021909d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = LoadData()\n",
    "load_data(dataset=\"mnist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40e941d-0308-407b-b46f-36add9b92193",
   "metadata": {},
   "source": [
    "The dvc stage and the config has been created for us. But these values are also available via the class.\n",
    "If we want to look at the output files, we can do as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0c0a9dc-b140-488c-a92f-99d00971f08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[WindowsPath('outs/0_x_train.npy'),\n WindowsPath('outs/0_y_train.npy'),\n WindowsPath('outs/0_x_test.npy'),\n WindowsPath('outs/0_y_test.npy')]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data.files.outs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefd27c4-5a6c-4838-a1bc-19872f226800",
   "metadata": {},
   "source": [
    "Note: An additional file containing the results will also be created and can be found as `load_data.files.json_file`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672fbd18-bb56-4a86-b154-904b5b45ef3e",
   "metadata": {},
   "source": [
    "The stage has not been executed yet, so no results are present. We can change that via `dvc repro`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adb00702-89f6-469f-9617-c85454cb67b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No results found!\n"
     ]
    },
    {
     "data": {
      "text/plain": "{}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data.results"
   ]
  },
  {
   "cell_type": "code",
   "id": "26dbfff0-eaee-4ab8-ac6d-01525e83424e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "!dvc repro"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running stage 'LoadData_0':\n",
      "> python -c \"from functions import LoadData; LoadData(id_=0).run()\"\n",
      "Generating lock file 'dvc.lock'\n",
      "Updating lock file 'dvc.lock'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-09 11:54:51.227324: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add dvc.lock\n",
      "Use `dvc push` to send your updates to remote storage.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "331c9012-e49c-451e-960c-c3f01b691ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'shape': [60000, 28, 28], 'targets': 10}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data.results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f599f3c-c1eb-4262-a85c-d9f4f72ebd95",
   "metadata": {},
   "source": [
    "Let us now create further stages that depend on this stage. \n",
    "By default every stage is unique and has the `id = 0`. But in some cases it might be handy to have one stage multiple times.\n",
    "This can be achieved by `DVCParams(multi_use=True)`, which allows for ids > 0. \n",
    "This can be interesting if you want to combine multiple data sources but it should not be used for multiple models, because we want to use DVC for that!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477e02d8-cb60-4ab0-b0ca-74dd22d5ceda",
   "metadata": {},
   "source": [
    "*Content of ExampleTensorflow01.py:FitModel*\n",
    "```python\n",
    "from pytrack import PyTrack, DVCParams\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class FitModel(PyTrack):\n",
    "    def __init__(self, id_=None, filter_=None):\n",
    "        super().__init__()\n",
    "        self.dvc = DVCParams(\n",
    "            outs=['model']\n",
    "        )\n",
    "        self.json_file = False\n",
    "        self.post_init(id_, filter_)\n",
    "\n",
    "    def __call__(self, exec_: bool = False, slurm: bool = False, force: bool = False,\n",
    "                 always_changed: bool = False):\n",
    "        self.dvc.deps = LoadData(id_=0).files.outs[:2]\n",
    "\n",
    "        self.parameters = {\"layer\": 128}\n",
    "        self.post_call(exec_=exec_, slurm=slurm, force=force, always_changed=always_changed)\n",
    "\n",
    "    def run(self):\n",
    "        self.pre_run()\n",
    "\n",
    "        load_data = LoadData(id_=0)\n",
    "\n",
    "        input_shape = load_data.results['shape'][1:]\n",
    "        target_size = load_data.results['targets']\n",
    "\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "            tf.keras.layers.Dense(self.parameters['layer'], activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(target_size)\n",
    "        ])\n",
    "\n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss=loss_fn,\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        with open(load_data.files.outs[0], 'rb') as f:\n",
    "            x_train = np.load(f)\n",
    "        with open(load_data.files.outs[1], 'rb') as f:\n",
    "            y_train = np.load(f)\n",
    "\n",
    "        model.fit(x_train, y_train, epochs=5)\n",
    "        model.save(str(self.files.outs[0]))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "589470b5-5897-4a30-af0e-cb2b8921d2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model = FitModel()\n",
    "fit_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b5e50a-0054-4931-9e04-e48b69bef199",
   "metadata": {},
   "source": [
    "*Content of ExampleTensorflow01.py:EvaluateModel*\n",
    "```python\n",
    "from pytrack import PyTrack, DVCParams\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "class EvaluateModel(PyTrack):\n",
    "\n",
    "    def __init__(self, id_=None, filter_=None):\n",
    "        super().__init__()\n",
    "        self.dvc = DVCParams(\n",
    "            metrics_no_cache=['metrics.json']\n",
    "        )\n",
    "        self.json_file = False\n",
    "        self.post_init(id_, filter_)\n",
    "\n",
    "    def __call__(self, exec_: bool = False, slurm: bool = False, force: bool = False,\n",
    "                 always_changed: bool = False):\n",
    "        self.parameters = {'verbose': 2}\n",
    "        self.dvc.deps = FitModel(id_=0).files.outs\n",
    "        self.dvc.deps += LoadData(id_=0).files.outs[2:]\n",
    "        self.post_call(exec_=exec_, slurm=slurm, force=force, always_changed=always_changed)\n",
    "\n",
    "    def run(self):\n",
    "        self.pre_run()\n",
    "\n",
    "        fit_model = FitModel(id_=0)\n",
    "\n",
    "        model = tf.keras.models.load_model(str(fit_model.files.outs[0]))\n",
    "\n",
    "        load_data = LoadData(id_=0)\n",
    "\n",
    "        with open(load_data.files.outs[2], 'rb') as f:\n",
    "            x_test = np.load(f)\n",
    "        with open(load_data.files.outs[3], 'rb') as f:\n",
    "            y_test = np.load(f)\n",
    "\n",
    "        out = model.evaluate(x_test, y_test, verbose=self.parameters['verbose'])\n",
    "\n",
    "        with open(self.files.metrics_no_cache[0], \"w\") as f:\n",
    "            json.dump(out, f)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "520144d3-79cd-4d03-bd98-699cfc195ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = EvaluateModel()\n",
    "eval_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a67cbe3-758c-41c1-bb15-db306228a69b",
   "metadata": {},
   "source": [
    "We have now created a `dvc.yaml` file containing all the information \n",
    "\n",
    "```yaml\n",
    "stages:\n",
    "  LoadData_0:\n",
    "    cmd: python -c \"from functions import LoadData; LoadData().run_dvc(id_=0)\"\n",
    "    params:\n",
    "    - config/params.json:\n",
    "      - LoadData.0\n",
    "    outs:\n",
    "    - outs\\0_LoadData.json\n",
    "    - outs\\0_x_test.npy\n",
    "    - outs\\0_x_train.npy\n",
    "    - outs\\0_y_test.npy\n",
    "    - outs\\0_y_train.npy\n",
    "  FitModel_0:\n",
    "    cmd: python -c \"from functions import FitModel; FitModel().run_dvc(id_=0)\"\n",
    "    deps:\n",
    "    - outs\\0_x_train.npy\n",
    "    - outs\\0_y_train.npy\n",
    "    params:\n",
    "    - config/params.json:\n",
    "      - FitModel.0\n",
    "    outs:\n",
    "    - outs\\0_model\n",
    "  EvaluateModel_0:\n",
    "    cmd: python -c \"from functions import EvaluateModel; EvaluateModel().run_dvc(id_=0)\"\n",
    "    deps:\n",
    "    - outs\\0_model\n",
    "    - outs\\0_x_test.npy\n",
    "    - outs\\0_y_test.npy\n",
    "    params:\n",
    "    - config/params.json:\n",
    "      - EvaluateModel.0\n",
    "    metrics:\n",
    "    - metrics\\0_metrics.json:\n",
    "        cache: false\n",
    "```\n",
    "and the respective parameters are stored in \n",
    "```json\n",
    "{\n",
    "  \"LoadData\": {\n",
    "    \"0\": {\n",
    "      \"dataset\": \"mnist\"\n",
    "    }\n",
    "  },\n",
    "  \"FitModel\": {\n",
    "    \"0\": {\n",
    "      \"layer\": 128\n",
    "    }\n",
    "  },\n",
    "  \"EvaluateModel\": {\n",
    "    \"0\": {\n",
    "      \"verbose\": 2\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344bb9ff-2e53-4428-8789-be314039e3ff",
   "metadata": {},
   "source": [
    "The dependency graph is also available via `dvc dag`\n",
    "```\n",
    "              +------------+        \n",
    "\n",
    "              | LoadData_0 |        \n",
    "\n",
    "              +------------+        \n",
    "\n",
    "             ***           ***      \n",
    "\n",
    "           **                 **    \n",
    "\n",
    "         **                     **  \n",
    "\n",
    "+------------+                    **\n",
    "\n",
    "| FitModel_0 |                  **  \n",
    "\n",
    "+------------+                **    \n",
    "\n",
    "             ***           ***      \n",
    "\n",
    "                **       **         \n",
    "\n",
    "                  **   **           \n",
    "\n",
    "            +-----------------+     \n",
    "\n",
    "            | EvaluateModel_0 |     \n",
    "\n",
    "            +-----------------+  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fc140a-6c12-4290-93bf-486ea9cb7b43",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can now use `dvc repro` to run all stages we have created and can look at the results in the respective folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "955a9d9b-9f3b-45f4-b28e-91522769fe5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 'LoadData_0' didn't change, skipping\n",
      "Running stage 'FitModel_0':\n",
      "> python -c \"from functions import FitModel; FitModel(id_=0).run()\"\n",
      "Epoch 1/5\n",
      "\n",
      "   1/1875 [..............................] - ETA: 10:05 - loss: 2.3944 - accuracy: 0.1250\n",
      "  67/1875 [>.............................] - ETA: 1s - loss: 1.1767 - accuracy: 0.6600   \n",
      " 129/1875 [=>............................] - ETA: 1s - loss: 0.8790 - accuracy: 0.7469\n",
      " 191/1875 [==>...........................] - ETA: 1s - loss: 0.7380 - accuracy: 0.7888\n",
      " 254/1875 [===>..........................] - ETA: 1s - loss: 0.6568 - accuracy: 0.8134\n",
      " 305/1875 [===>..........................] - ETA: 1s - loss: 0.6146 - accuracy: 0.8251\n",
      " 343/1875 [====>.........................] - ETA: 1s - loss: 0.5833 - accuracy: 0.8335\n",
      " 392/1875 [=====>........................] - ETA: 1s - loss: 0.5506 - accuracy: 0.8430\n",
      " 445/1875 [======>.......................] - ETA: 1s - loss: 0.5271 - accuracy: 0.8497\n",
      " 506/1875 [=======>......................] - ETA: 1s - loss: 0.5005 - accuracy: 0.8563\n",
      " 575/1875 [========>.....................] - ETA: 1s - loss: 0.4749 - accuracy: 0.8630\n",
      " 643/1875 [=========>....................] - ETA: 1s - loss: 0.4525 - accuracy: 0.8692\n",
      " 711/1875 [==========>...................] - ETA: 0s - loss: 0.4330 - accuracy: 0.8741\n",
      " 775/1875 [===========>..................] - ETA: 0s - loss: 0.4197 - accuracy: 0.8779\n",
      " 838/1875 [============>.................] - ETA: 0s - loss: 0.4087 - accuracy: 0.8811\n",
      " 903/1875 [=============>................] - ETA: 0s - loss: 0.3957 - accuracy: 0.8846\n",
      " 967/1875 [==============>...............] - ETA: 0s - loss: 0.3845 - accuracy: 0.8874\n",
      "1032/1875 [===============>..............] - ETA: 0s - loss: 0.3749 - accuracy: 0.8904\n",
      "1099/1875 [================>.............] - ETA: 0s - loss: 0.3644 - accuracy: 0.8937\n",
      "1167/1875 [=================>............] - ETA: 0s - loss: 0.3565 - accuracy: 0.8961\n",
      "1234/1875 [==================>...........] - ETA: 0s - loss: 0.3489 - accuracy: 0.8979\n",
      "1296/1875 [===================>..........] - ETA: 0s - loss: 0.3427 - accuracy: 0.8996\n",
      "1358/1875 [====================>.........] - ETA: 0s - loss: 0.3356 - accuracy: 0.9015\n",
      "1420/1875 [=====================>........] - ETA: 0s - loss: 0.3300 - accuracy: 0.9033\n",
      "1486/1875 [======================>.......] - ETA: 0s - loss: 0.3237 - accuracy: 0.9050\n",
      "1553/1875 [=======================>......] - ETA: 0s - loss: 0.3176 - accuracy: 0.9072\n",
      "1621/1875 [========================>.....] - ETA: 0s - loss: 0.3125 - accuracy: 0.9087\n",
      "1689/1875 [==========================>...] - ETA: 0s - loss: 0.3078 - accuracy: 0.9099\n",
      "1756/1875 [===========================>..] - ETA: 0s - loss: 0.3033 - accuracy: 0.9110\n",
      "1825/1875 [============================>.] - ETA: 0s - loss: 0.2986 - accuracy: 0.9125\n",
      "1875/1875 [==============================] - 2s 805us/step - loss: 0.2958 - accuracy: 0.9133\n",
      "Epoch 2/5\n",
      "\n",
      "   1/1875 [..............................] - ETA: 1s - loss: 0.0864 - accuracy: 0.9688\n",
      "  64/1875 [>.............................] - ETA: 1s - loss: 0.1344 - accuracy: 0.9609\n",
      " 129/1875 [=>............................] - ETA: 1s - loss: 0.1432 - accuracy: 0.9586\n",
      " 189/1875 [==>...........................] - ETA: 1s - loss: 0.1457 - accuracy: 0.9573\n",
      " 254/1875 [===>..........................] - ETA: 1s - loss: 0.1505 - accuracy: 0.9561\n",
      " 314/1875 [====>.........................] - ETA: 1s - loss: 0.1523 - accuracy: 0.9554\n",
      " 378/1875 [=====>........................] - ETA: 1s - loss: 0.1512 - accuracy: 0.9557\n",
      " 446/1875 [======>.......................] - ETA: 1s - loss: 0.1522 - accuracy: 0.9561\n",
      " 511/1875 [=======>......................] - ETA: 1s - loss: 0.1513 - accuracy: 0.9559\n",
      " 567/1875 [========>.....................] - ETA: 1s - loss: 0.1517 - accuracy: 0.9562\n",
      " 622/1875 [========>.....................] - ETA: 1s - loss: 0.1490 - accuracy: 0.9570\n",
      " 680/1875 [=========>....................] - ETA: 0s - loss: 0.1466 - accuracy: 0.9572\n",
      " 746/1875 [==========>...................] - ETA: 0s - loss: 0.1483 - accuracy: 0.9564\n",
      " 812/1875 [===========>..................] - ETA: 0s - loss: 0.1471 - accuracy: 0.9571\n",
      " 878/1875 [=============>................] - ETA: 0s - loss: 0.1478 - accuracy: 0.9565\n",
      " 948/1875 [==============>...............] - ETA: 0s - loss: 0.1482 - accuracy: 0.9564\n",
      "1017/1875 [===============>..............] - ETA: 0s - loss: 0.1474 - accuracy: 0.9567\n",
      "1083/1875 [================>.............] - ETA: 0s - loss: 0.1476 - accuracy: 0.9564"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-09 11:55:02.414290: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll\n",
      "2021-06-09 11:55:04.724504: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library nvcuda.dll\n",
      "2021-06-09 11:55:04.749461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:09:00.0 name: NVIDIA GeForce GTX 1050 Ti computeCapability: 6.1\n",
      "coreClock: 1.43GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s\n",
      "2021-06-09 11:55:04.749488: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll\n",
      "2021-06-09 11:55:04.757393: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublas64_11.dll\n",
      "2021-06-09 11:55:04.757423: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublasLt64_11.dll\n",
      "2021-06-09 11:55:04.761410: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cufft64_10.dll\n",
      "2021-06-09 11:55:04.762906: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library curand64_10.dll\n",
      "2021-06-09 11:55:04.768156: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cusolver64_11.dll\n",
      "2021-06-09 11:55:04.771675: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cusparse64_11.dll\n",
      "2021-06-09 11:55:04.772679: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found\n",
      "2021-06-09 11:55:04.772697: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-06-09 11:55:04.773132: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-06-09 11:55:04.774150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-09 11:55:04.774172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n",
      "2021-06-09 11:55:05.403706: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-06-09 11:55:13.204654: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2021-06-09 11:55:14.952915: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll\n",
      "2021-06-09 11:55:17.245335: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library nvcuda.dll\n",
      "2021-06-09 11:55:17.268795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:09:00.0 name: NVIDIA GeForce GTX 1050 Ti computeCapability: 6.1\n",
      "coreClock: 1.43GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s\n",
      "2021-06-09 11:55:17.268822: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll\n",
      "2021-06-09 11:55:17.275625: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublas64_11.dll\n",
      "2021-06-09 11:55:17.275655: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublasLt64_11.dll\n",
      "2021-06-09 11:55:17.279206: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cufft64_10.dll\n",
      "2021-06-09 11:55:17.280610: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library curand64_10.dll\n",
      "2021-06-09 11:55:17.285302: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cusolver64_11.dll\n",
      "2021-06-09 11:55:17.288416: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cusparse64_11.dll\n",
      "2021-06-09 11:55:17.289386: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found\n",
      "2021-06-09 11:55:17.289402: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-06-09 11:55:17.289850: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-06-09 11:55:17.290586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-09 11:55:17.290599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n",
      "2021-06-09 11:55:18.195860: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1145/1875 [=================>............] - ETA: 0s - loss: 0.1471 - accuracy: 0.9568\n",
      "1207/1875 [==================>...........] - ETA: 0s - loss: 0.1473 - accuracy: 0.9567\n",
      "1268/1875 [===================>..........] - ETA: 0s - loss: 0.1475 - accuracy: 0.9566\n",
      "1331/1875 [====================>.........] - ETA: 0s - loss: 0.1476 - accuracy: 0.9565\n",
      "1397/1875 [=====================>........] - ETA: 0s - loss: 0.1460 - accuracy: 0.9569\n",
      "1466/1875 [======================>.......] - ETA: 0s - loss: 0.1452 - accuracy: 0.9570\n",
      "1535/1875 [=======================>......] - ETA: 0s - loss: 0.1451 - accuracy: 0.9572\n",
      "1606/1875 [========================>.....] - ETA: 0s - loss: 0.1452 - accuracy: 0.9571\n",
      "1676/1875 [=========================>....] - ETA: 0s - loss: 0.1448 - accuracy: 0.9571\n",
      "1746/1875 [==========================>...] - ETA: 0s - loss: 0.1438 - accuracy: 0.9573\n",
      "1813/1875 [============================>.] - ETA: 0s - loss: 0.1441 - accuracy: 0.9572\n",
      "1875/1875 [==============================] - 1s 781us/step - loss: 0.1430 - accuracy: 0.9576\n",
      "Epoch 3/5\n",
      "\n",
      "   1/1875 [..............................] - ETA: 1s - loss: 0.0274 - accuracy: 1.0000\n",
      "  69/1875 [>.............................] - ETA: 1s - loss: 0.1082 - accuracy: 0.9669\n",
      " 137/1875 [=>............................] - ETA: 1s - loss: 0.1114 - accuracy: 0.9656\n",
      " 204/1875 [==>...........................] - ETA: 1s - loss: 0.1115 - accuracy: 0.9660\n",
      " 271/1875 [===>..........................] - ETA: 1s - loss: 0.1105 - accuracy: 0.9655\n",
      " 338/1875 [====>.........................] - ETA: 1s - loss: 0.1126 - accuracy: 0.9649\n",
      " 408/1875 [=====>........................] - ETA: 1s - loss: 0.1138 - accuracy: 0.9655\n",
      " 474/1875 [======>.......................] - ETA: 1s - loss: 0.1129 - accuracy: 0.9657\n",
      " 534/1875 [=======>......................] - ETA: 1s - loss: 0.1120 - accuracy: 0.9661\n",
      " 592/1875 [========>.....................] - ETA: 0s - loss: 0.1131 - accuracy: 0.9658\n",
      " 657/1875 [=========>....................] - ETA: 0s - loss: 0.1126 - accuracy: 0.9657\n",
      " 709/1875 [==========>...................] - ETA: 0s - loss: 0.1119 - accuracy: 0.9660\n",
      " 771/1875 [===========>..................] - ETA: 0s - loss: 0.1137 - accuracy: 0.9660\n",
      " 838/1875 [============>.................] - ETA: 0s - loss: 0.1140 - accuracy: 0.9658\n",
      " 906/1875 [=============>................] - ETA: 0s - loss: 0.1123 - accuracy: 0.9665\n",
      " 973/1875 [==============>...............] - ETA: 0s - loss: 0.1124 - accuracy: 0.9665\n",
      "1041/1875 [===============>..............] - ETA: 0s - loss: 0.1119 - accuracy: 0.9666\n",
      "1105/1875 [================>.............] - ETA: 0s - loss: 0.1110 - accuracy: 0.9666\n",
      "1168/1875 [=================>............] - ETA: 0s - loss: 0.1110 - accuracy: 0.9667\n",
      "1237/1875 [==================>...........] - ETA: 0s - loss: 0.1101 - accuracy: 0.9668\n",
      "1301/1875 [===================>..........] - ETA: 0s - loss: 0.1101 - accuracy: 0.9669\n",
      "1368/1875 [====================>.........] - ETA: 0s - loss: 0.1099 - accuracy: 0.9669\n",
      "1431/1875 [=====================>........] - ETA: 0s - loss: 0.1095 - accuracy: 0.9671\n",
      "1499/1875 [======================>.......] - ETA: 0s - loss: 0.1081 - accuracy: 0.9675\n",
      "1566/1875 [========================>.....] - ETA: 0s - loss: 0.1078 - accuracy: 0.9676\n",
      "1631/1875 [=========================>....] - ETA: 0s - loss: 0.1074 - accuracy: 0.9676\n",
      "1698/1875 [==========================>...] - ETA: 0s - loss: 0.1071 - accuracy: 0.9679\n",
      "1762/1875 [===========================>..] - ETA: 0s - loss: 0.1068 - accuracy: 0.9680\n",
      "1821/1875 [============================>.] - ETA: 0s - loss: 0.1063 - accuracy: 0.9681\n",
      "1875/1875 [==============================] - 1s 776us/step - loss: 0.1064 - accuracy: 0.9681\n",
      "Epoch 4/5\n",
      "\n",
      "   1/1875 [..............................] - ETA: 1s - loss: 0.0094 - accuracy: 1.0000\n",
      "  67/1875 [>.............................] - ETA: 1s - loss: 0.0975 - accuracy: 0.9725\n",
      " 134/1875 [=>............................] - ETA: 1s - loss: 0.0897 - accuracy: 0.9748\n",
      " 203/1875 [==>...........................] - ETA: 1s - loss: 0.0903 - accuracy: 0.9734\n",
      " 270/1875 [===>..........................] - ETA: 1s - loss: 0.0874 - accuracy: 0.9738\n",
      " 340/1875 [====>.........................] - ETA: 1s - loss: 0.0864 - accuracy: 0.9742\n",
      " 410/1875 [=====>........................] - ETA: 1s - loss: 0.0844 - accuracy: 0.9752\n",
      " 478/1875 [======>.......................] - ETA: 1s - loss: 0.0851 - accuracy: 0.9748\n",
      " 546/1875 [=======>......................] - ETA: 0s - loss: 0.0846 - accuracy: 0.9748\n",
      " 614/1875 [========>.....................] - ETA: 0s - loss: 0.0862 - accuracy: 0.9740\n",
      " 683/1875 [=========>....................] - ETA: 0s - loss: 0.0860 - accuracy: 0.9739\n",
      " 751/1875 [===========>..................] - ETA: 0s - loss: 0.0848 - accuracy: 0.9742\n",
      " 820/1875 [============>.................] - ETA: 0s - loss: 0.0849 - accuracy: 0.9738\n",
      " 889/1875 [=============>................] - ETA: 0s - loss: 0.0858 - accuracy: 0.9734\n",
      " 956/1875 [==============>...............] - ETA: 0s - loss: 0.0862 - accuracy: 0.9733\n",
      "1024/1875 [===============>..............] - ETA: 0s - loss: 0.0869 - accuracy: 0.9732\n",
      "1091/1875 [================>.............] - ETA: 0s - loss: 0.0862 - accuracy: 0.9734\n",
      "1159/1875 [=================>............] - ETA: 0s - loss: 0.0861 - accuracy: 0.9735\n",
      "1229/1875 [==================>...........] - ETA: 0s - loss: 0.0858 - accuracy: 0.9736\n",
      "1298/1875 [===================>..........] - ETA: 0s - loss: 0.0853 - accuracy: 0.9739\n",
      "1365/1875 [====================>.........] - ETA: 0s - loss: 0.0849 - accuracy: 0.9740\n",
      "1434/1875 [=====================>........] - ETA: 0s - loss: 0.0853 - accuracy: 0.9738\n",
      "1503/1875 [=======================>......] - ETA: 0s - loss: 0.0851 - accuracy: 0.9739\n",
      "1571/1875 [========================>.....] - ETA: 0s - loss: 0.0851 - accuracy: 0.9738\n",
      "1640/1875 [=========================>....] - ETA: 0s - loss: 0.0853 - accuracy: 0.9738\n",
      "1710/1875 [==========================>...] - ETA: 0s - loss: 0.0854 - accuracy: 0.9737\n",
      "1776/1875 [===========================>..] - ETA: 0s - loss: 0.0852 - accuracy: 0.9739\n",
      "1843/1875 [============================>.] - ETA: 0s - loss: 0.0856 - accuracy: 0.9739\n",
      "1875/1875 [==============================] - 1s 742us/step - loss: 0.0858 - accuracy: 0.9738\n",
      "Epoch 5/5\n",
      "\n",
      "   1/1875 [..............................] - ETA: 1s - loss: 0.0539 - accuracy: 0.9688\n",
      "  68/1875 [>.............................] - ETA: 1s - loss: 0.0644 - accuracy: 0.9784\n",
      " 135/1875 [=>............................] - ETA: 1s - loss: 0.0677 - accuracy: 0.9785\n",
      " 202/1875 [==>...........................] - ETA: 1s - loss: 0.0673 - accuracy: 0.9779\n",
      " 270/1875 [===>..........................] - ETA: 1s - loss: 0.0675 - accuracy: 0.9779\n",
      " 337/1875 [====>.........................] - ETA: 1s - loss: 0.0681 - accuracy: 0.9781\n",
      " 404/1875 [=====>........................] - ETA: 1s - loss: 0.0713 - accuracy: 0.9766\n",
      " 473/1875 [======>.......................] - ETA: 1s - loss: 0.0718 - accuracy: 0.9767\n",
      " 540/1875 [=======>......................] - ETA: 0s - loss: 0.0726 - accuracy: 0.9770\n",
      " 608/1875 [========>.....................] - ETA: 0s - loss: 0.0724 - accuracy: 0.9776\n",
      " 676/1875 [=========>....................] - ETA: 0s - loss: 0.0726 - accuracy: 0.9776\n",
      " 743/1875 [==========>...................] - ETA: 0s - loss: 0.0744 - accuracy: 0.9773\n",
      " 811/1875 [===========>..................] - ETA: 0s - loss: 0.0747 - accuracy: 0.9773\n",
      " 878/1875 [=============>................] - ETA: 0s - loss: 0.0757 - accuracy: 0.9769\n",
      " 946/1875 [==============>...............] - ETA: 0s - loss: 0.0757 - accuracy: 0.9772\n",
      "1014/1875 [===============>..............] - ETA: 0s - loss: 0.0748 - accuracy: 0.9773\n",
      "1083/1875 [================>.............] - ETA: 0s - loss: 0.0744 - accuracy: 0.9773\n",
      "1150/1875 [=================>............] - ETA: 0s - loss: 0.0744 - accuracy: 0.9771\n",
      "1217/1875 [==================>...........] - ETA: 0s - loss: 0.0742 - accuracy: 0.9771\n",
      "1286/1875 [===================>..........] - ETA: 0s - loss: 0.0742 - accuracy: 0.9771\n",
      "1353/1875 [====================>.........] - ETA: 0s - loss: 0.0740 - accuracy: 0.9771\n",
      "1421/1875 [=====================>........] - ETA: 0s - loss: 0.0745 - accuracy: 0.9770\n",
      "1489/1875 [======================>.......] - ETA: 0s - loss: 0.0743 - accuracy: 0.9770\n",
      "1555/1875 [=======================>......] - ETA: 0s - loss: 0.0743 - accuracy: 0.9770\n",
      "1623/1875 [========================>.....] - ETA: 0s - loss: 0.0739 - accuracy: 0.9770\n",
      "1688/1875 [==========================>...] - ETA: 0s - loss: 0.0737 - accuracy: 0.9770\n",
      "1756/1875 [===========================>..] - ETA: 0s - loss: 0.0742 - accuracy: 0.9770\n",
      "1824/1875 [============================>.] - ETA: 0s - loss: 0.0741 - accuracy: 0.9770\n",
      "1875/1875 [==============================] - 1s 750us/step - loss: 0.0742 - accuracy: 0.9769\n",
      "Updating lock file 'dvc.lock'\n",
      "\n",
      "Running stage 'EvaluateModel_0':\n",
      "> python -c \"from functions import EvaluateModel; EvaluateModel(id_=0).run()\"\n",
      "313/313 - 0s - loss: 0.0761 - accuracy: 0.9759\n",
      "Updating lock file 'dvc.lock'\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add dvc.lock\n",
      "Use `dvc push` to send your updates to remote storage.\n"
     ]
    }
   ],
   "source": [
    "!dvc repro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "!dvc destroy -f"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "temp_dir.cleanup()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}